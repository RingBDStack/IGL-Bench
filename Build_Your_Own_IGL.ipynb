{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Addâ€¯Yourâ€¯Ownâ€¯Algorithm to IGL-Bench\n",
    "\n",
    "The following shows the steps required to register a brandâ€‘new algorithm inside IGL_Bench.\n",
    "\n",
    "> Everything else (data loading, masking, seeds, config loading) is already handled by the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 1: Folder layout and file names\n",
    "\n",
    "IGL_Bench discovers solvers and configs **by name**(string). Create the following two files:\n",
    "\n",
    "```\n",
    "IGL_Bench/\n",
    "  algorithm/\n",
    "    MyGNN/\n",
    "      __init__.py\n",
    "      solver.py         # â† implements MyGNN_node_solver or MyGNN_graph_solver\n",
    "config/\n",
    "  topo_global/\n",
    "    MyGNN.yml           # â† hyper-parameter config\n",
    "```\n",
    "\n",
    "> Replace topo_global with class, topo_local, or topology to match your imbalance type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“„ Step 2: Write config/topo_global/MyGNN.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = '''\\\n",
    "algorithm: \"MyGNN\"\n",
    "task: \"node\"\n",
    "\n",
    "lr: 0.005\n",
    "hidden_dim: 128\n",
    "dropout: 0.5\n",
    "weight_decay: 0.0005\n",
    "epoch: 300\n",
    "least_epoch: 40\n",
    "\n",
    "n_layer: 2\n",
    "'''\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 3: Implement algorithm/MyGNN/solver.py\n",
    "\n",
    "The solver must expose a class `<Algorithm>_<task>_solver` and return acc/bacc/mf1/roc from `test()`.\n",
    "\n",
    "### ðŸ“¦ Dataset object\n",
    "\n",
    "In `__init__`, the provided `dataset` contains the following preprocessed attributes:\n",
    "- `x`, `y`, `adj`, `edge_index`, `adj_norm` (PyTorch tensor format)\n",
    "- `train_mask`, `val_mask`, `test_mask` (boolean tensors)\n",
    "- `train_index`, `val_index`, `test_index` (list arrays)\n",
    "\n",
    "These are ready to use and no additional preprocessing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IGL_Bench.backbone.gcn import GCN_node_sparse\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "class MyGNN_node_solver:\n",
    "    def __init__(self, config, dataset, device=\"cuda\"):\n",
    "        self.cfg = config\n",
    "        self.data = dataset.to(device)\n",
    "        self.device = device\n",
    "        n_feat = self.data.num_features\n",
    "        n_class = int(self.data.y.max().item() + 1)\n",
    "        self.model = GCN_node_sparse(n_feat, self.cfg.hidden_dim, n_class,\n",
    "                                     self.cfg.n_layer, self.cfg.dropout).to(device)\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=self.cfg.lr,\n",
    "                                    weight_decay=self.cfg.weight_decay)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if hasattr(self.model, \"reset_parameters\"):\n",
    "            self.model.reset_parameters()\n",
    "        for g in self.opt.param_groups:\n",
    "            g[\"lr\"] = self.cfg.lr\n",
    "\n",
    "    def train(self):\n",
    "        self.reset_parameters()\n",
    "        patience, counter, best = 10, 0, 0.0\n",
    "        for epoch in range(1, self.cfg.epoch + 1):\n",
    "            self.model.train(); self.opt.zero_grad()\n",
    "            logits = self.model(self.data.x, self.data.edge_index)\n",
    "            loss = F.cross_entropy(logits[self.data.train_mask], self.data.y[self.data.train_mask])\n",
    "            loss.backward(); self.opt.step()\n",
    "            acc_val = self._eval(\"val\")\n",
    "            if acc_val > best:\n",
    "                best, counter = acc_val, 0\n",
    "            else:\n",
    "                counter += 1\n",
    "            if counter >= patience and epoch >= self.cfg.least_epoch:\n",
    "                print(f\"Early stop at epoch {epoch}\"); break\n",
    "\n",
    "    def _eval(self, split=\"val\"):\n",
    "        self.model.eval()\n",
    "        mask = getattr(self.data, f\"{split}_mask\")\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(self.data.x, self.data.edge_index)[mask]\n",
    "        pred = logits.argmax(dim=1).cpu(); true = self.data.y[mask].cpu()\n",
    "        return accuracy_score(true, pred)\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval(); mask = self.data.test_mask\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(self.data.x, self.data.edge_index)[mask]\n",
    "        pred = logits.argmax(dim=1).cpu()\n",
    "        prob = F.softmax(logits, dim=1).cpu()\n",
    "        y = self.data.y[mask].cpu()\n",
    "        acc  = accuracy_score(y, pred)\n",
    "        bacc = balanced_accuracy_score(y, pred)\n",
    "        mf1  = f1_score(y, pred, average=\"macro\")\n",
    "        roc  = roc_auc_score(y, prob, multi_class=\"ovr\", average=\"macro\")\n",
    "        return acc, bacc, mf1, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 4: Smoke test your algorithm\n",
    "After saving solver.py and MyGNN.yml, test them with the Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IGL_Bench as igl\n",
    "\n",
    "dataset = igl.dataset.Dataset(\n",
    "    task=\"node\",\n",
    "    data_name=\"Cora\",\n",
    "    imb_type=\"topo_global\",\n",
    "    imb_level=\"high\"\n",
    ").load_dataset()\n",
    "\n",
    "cfg = igl.config.load_conf(task=\"node\", imbtype=\"topo_global\", algorithm=\"MyGNN\")\n",
    "solver = igl.manage.Manager(cfg, dataset)\n",
    "solver.run(num_runs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- Your solver.py needs to define __init__(), train(), reset_parameters(), and test()\n",
    "- Configs are loaded dynamically using the algorithm name\n",
    "- Return (acc, bacc, macro_f1, auc_roc) in order\n",
    "\n",
    "Your algorithm is now benchmark-ready!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
